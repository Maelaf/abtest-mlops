{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88441086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('../scripts')))\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fafe7ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import dvc.api\n",
    "from processing import processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee4694f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from gittypes import tbd\n",
    "import pandas as pd\n",
    "import Plots\n",
    "import scipy.stats as scs\n",
    "import random\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import export_graphviz\n",
    "from six import StringIO\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "from sklearn import tree\n",
    "import scipy.stats as stat\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a69ab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"../Data/data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "825879c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "processing = processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57d96ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file read as csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auction_id</th>\n",
       "      <th>experiment</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>device_make</th>\n",
       "      <th>platform_os</th>\n",
       "      <th>browser</th>\n",
       "      <th>yes</th>\n",
       "      <th>no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ef63-77a7-448b-bd1e-075f42c55e39</td>\n",
       "      <td>exposed</td>\n",
       "      <td>2020-07-10</td>\n",
       "      <td>8</td>\n",
       "      <td>Generic Smartphone</td>\n",
       "      <td>6</td>\n",
       "      <td>Chrome Mobile</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000eabc5-17ce-4137-8efe-44734d914446</td>\n",
       "      <td>exposed</td>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>10</td>\n",
       "      <td>Generic Smartphone</td>\n",
       "      <td>6</td>\n",
       "      <td>Chrome Mobile</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0016d14a-ae18-4a02-a204-6ba53b52f2ed</td>\n",
       "      <td>exposed</td>\n",
       "      <td>2020-07-05</td>\n",
       "      <td>2</td>\n",
       "      <td>E5823</td>\n",
       "      <td>6</td>\n",
       "      <td>Chrome Mobile WebView</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00187412-2932-4542-a8ef-3633901c98d9</td>\n",
       "      <td>control</td>\n",
       "      <td>2020-07-03</td>\n",
       "      <td>15</td>\n",
       "      <td>Samsung SM-A705FN</td>\n",
       "      <td>6</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001a7785-d3fe-4e11-a344-c8735acacc2c</td>\n",
       "      <td>control</td>\n",
       "      <td>2020-07-03</td>\n",
       "      <td>15</td>\n",
       "      <td>Generic Smartphone</td>\n",
       "      <td>6</td>\n",
       "      <td>Chrome Mobile</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             auction_id experiment        date  hour  \\\n",
       "0  0008ef63-77a7-448b-bd1e-075f42c55e39    exposed  2020-07-10     8   \n",
       "1  000eabc5-17ce-4137-8efe-44734d914446    exposed  2020-07-07    10   \n",
       "2  0016d14a-ae18-4a02-a204-6ba53b52f2ed    exposed  2020-07-05     2   \n",
       "3  00187412-2932-4542-a8ef-3633901c98d9    control  2020-07-03    15   \n",
       "4  001a7785-d3fe-4e11-a344-c8735acacc2c    control  2020-07-03    15   \n",
       "\n",
       "          device_make  platform_os                browser  yes  no  \n",
       "0  Generic Smartphone            6          Chrome Mobile    0   0  \n",
       "1  Generic Smartphone            6          Chrome Mobile    0   0  \n",
       "2               E5823            6  Chrome Mobile WebView    0   1  \n",
       "3   Samsung SM-A705FN            6               Facebook    0   0  \n",
       "4  Generic Smartphone            6          Chrome Mobile    0   0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= processing.read_csv(csv_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa8c4c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(tag, path='Data/clean_data.csv', repo='https://github.com/daniEL2371/abtest-mlops'):\n",
    "    rev = tag\n",
    "    data_url = dvc.api.get_url(path=path, repo=repo, rev=rev)\n",
    "    df = pd.read_csv(data_url)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fc75296",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def drop_no_responds(df):\n",
    "    cleaned_df = df.query(\"not (yes == 0 & no == 0)\")\n",
    "    return cleaned_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d43fa1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_model(file_name):\n",
    "    with open(f\"../models/{file_name}.pkl\", \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def write_model(file_name, model):\n",
    "    with open(f\"../models/{file_name}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56edb548",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = drop_no_responds(df)\n",
    "cleaned_df['aware'] = cleaned_df['yes'].map(lambda x: x==1)\n",
    "cleaned_df = cleaned_df.drop(columns = ['yes', 'no', 'auction_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56347fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cleaned_data():\n",
    "    CLEANED_CSV_PATH = \"../Data/clean_data.csv\"\n",
    "    helper.save_csv(cleaned_df, CLEANED_CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59179723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c46a478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0204aba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "def encode_labels(df):\n",
    "    date_encoder = preprocessing.LabelEncoder()\n",
    "    device_encoder = preprocessing.LabelEncoder()\n",
    "    browser_encoder = preprocessing.LabelEncoder()\n",
    "    experiment_encoder = preprocessing.LabelEncoder()\n",
    "    aware_encoder = preprocessing.LabelEncoder()\n",
    "    \n",
    "    df['date'] = date_encoder.fit_transform(df['date'])\n",
    "    df['device_make'] = device_encoder.fit_transform(df['device_make'])\n",
    "    df['browser'] = browser_encoder.fit_transform(df['browser'])\n",
    "    df['experiment'] = experiment_encoder.fit_transform(cleaned_df['experiment'])\n",
    "    df['browser'] = aware_encoder.fit_transform(df['browser'])\n",
    "    df['aware'] = aware_encoder.fit_transform(df['aware'])\n",
    "\n",
    "\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62761df5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "216678aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting database\n",
    "\n",
    "def feature_data(cleaned_df):\n",
    "    \n",
    "    broweser_df = cleaned_df[[\"experiment\", \"hour\", \"date\", 'device_make', 'browser', 'aware']]\n",
    "    platfrom_df = cleaned_df[[\"experiment\", \"hour\", \"date\", 'device_make', 'platform_os', 'aware']]\n",
    "\n",
    "    return broweser_df, platfrom_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31301bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d9be274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_encoded_df():\n",
    "    \n",
    "    broweser_df, platfrom_df = feature_data(encoded_df)\n",
    "    helper.save_csv(broweser_df, \"../Data/clean_data.csv\")\n",
    "    helper.save_csv(platfrom_df, \"../Data/clean_data.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd83c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f3275a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91585274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f911c935",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreesModel:\n",
    "    \n",
    "    def __init__(self, X_train, X_test, y_train, y_test, max_depth=5):\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        self.clf = DecisionTreeClassifier(max_depth=4)\n",
    "        \n",
    "    def train(self, folds=1):\n",
    "        \n",
    "        kf = KFold(n_splits = folds)\n",
    "        \n",
    "        iterator = kf.split(self.X_train)\n",
    "        \n",
    "        loss_arr = []\n",
    "        acc_arr = []\n",
    "        for i in range(folds):\n",
    "            train_index, valid_index = next(iterator)\n",
    "            \n",
    "            X_train, y_train = self.X_train.iloc[train_index], self.y_train.iloc[train_index]\n",
    "            X_valid, y_valid = self.X_train.iloc[valid_index], self.y_train.iloc[valid_index]\n",
    "                        \n",
    "            self.clf = self.clf.fit(X_train, y_train)\n",
    "            \n",
    "            vali_pred = self.clf.predict(X_valid)\n",
    "            \n",
    "            accuracy = self.calculate_score(y_valid\n",
    "                                              , vali_pred)\n",
    "            \n",
    "            loss = loss_function(y_valid, vali_pred)\n",
    "            \n",
    "            self.__printAccuracy(accuracy, i, label=\"Validation\")\n",
    "            self.__printLoss(loss, i, label=\"Validation\")\n",
    "            print()\n",
    "            \n",
    "            acc_arr.append(accuracy)\n",
    "            loss_arr.append(loss)\n",
    "\n",
    "            \n",
    "        return self.clf, acc_arr, loss_arr\n",
    "    \n",
    "    def test(self):\n",
    "        \n",
    "        y_pred = self.clf.predict(self.X_test)\n",
    "        \n",
    "        accuracy = self.calculate_score(y_pred, self.y_test)\n",
    "        self.__printAccuracy(accuracy, label=\"Test\")\n",
    "        \n",
    "        report = self.report(y_pred, self.y_test)\n",
    "        matrix = self.confusion_matrix(y_pred, self.y_test)\n",
    "        \n",
    "        loss = loss_function(self.y_test, y_pred)\n",
    "        \n",
    "        return accuracy, loss,  report, matrix\n",
    "    \n",
    "    def get_feature_importance(self):\n",
    "        importance = self.clf.feature_importances_\n",
    "        fi_df = pd.DataFrame()\n",
    "        \n",
    "        fi_df['feature'] = self.X_train.columns.to_list()\n",
    "        fi_df['feature_importances'] = importance\n",
    "        \n",
    "        return fi_df\n",
    "    \n",
    "    def __printAccuracy(self, acc, step=1, label=\"\"):\n",
    "        print(f\"step {step}: {label} Accuracy of DecisionTreesModel is: {acc:.3f}\")\n",
    "    \n",
    "    def __printLoss(self, loss, step=1, label=\"\"):\n",
    "        print(f\"step {step}: {label} Loss of DecisionTreesModel is: {loss:.3f}\")\n",
    "    \n",
    "    def calculate_score(self, pred, actual):\n",
    "        return metrics.accuracy_score(actual, pred)\n",
    "    \n",
    "    def report(self, pred, actual):\n",
    "        print(\"Test Metrics\")\n",
    "        print(\"================\")\n",
    "        print(metrics.classification_report(pred, actual))\n",
    "        return metrics.classification_report(pred, actual)\n",
    "    \n",
    "    def confusion_matrix(self, pred, actual):\n",
    "        ax=sns.heatmap(pd.DataFrame(metrics.confusion_matrix(pred, actual)))\n",
    "        plt.title('Confusion matrix')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        return metrics.confusion_matrix(pred, actual)\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6440b76",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'TypeGuard' from 'typing' (C:\\Users\\Maelaf ES\\anaconda3\\lib\\typing.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-28131117fc04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mProtocol\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTypeGuard\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplatform_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'enc-platform-df'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbrowser_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'enc-browser-df'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'TypeGuard' from 'typing' (C:\\Users\\Maelaf ES\\anaconda3\\lib\\typing.py)"
     ]
    }
   ],
   "source": [
    "from typing_extensions import Protocol\n",
    "from typing import TypeGuard\n",
    "platform_df = get_data('enc-platform-df')\n",
    "\n",
    "browser_df = get_data('enc-browser-df')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c204b698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Encoded Dataframe containing the the platfrom column\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'platform_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-2a2447213f4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"1. Encoded Dataframe containing the the platfrom column\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplatform_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'platform_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"1. Encoded Dataframe containing the the platfrom column\")\n",
    "platform_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b733d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Encoded Dataframe containing the the browser column\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'browser_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-d2115bcf57b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"2. Encoded Dataframe containing the the browser column\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbrowser_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'browser_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"2. Encoded Dataframe containing the the browser column\")\n",
    "browser_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4207f161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea8bf7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665270d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e240c328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "493c8d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mlflow\n",
    "# import datetime\n",
    "# Current_Date = datetime.datetime.today()\n",
    "\n",
    "# mlflow.set_experiment('ML_Approach_ABTEST-' + str(Current_Date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e6ad21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2dc14679",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'browser_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-29712dc92063>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfeature_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"experiment\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"hour\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"date\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'device_make'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'browser'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbrowser_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature_cols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbrowser_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'aware'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'browser_df' is not defined"
     ]
    }
   ],
   "source": [
    "# feature_cols = [\"experiment\", \"hour\", \"date\", 'device_make', \"platform_os\",  \"browser\"]\n",
    "feature_cols = [\"experiment\", \"hour\", \"date\", 'device_make', 'browser']\n",
    "\n",
    "X = browser_df[feature_cols]\n",
    "y = browser_df[['aware']]\n",
    "\n",
    "test_size = 0.1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c916f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1ac477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bd749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionTreesModel = DecisionTreesModel(X_train, X_test,  y_train, y_test)\n",
    "\n",
    "folds = 5\n",
    "clf, acc_arr, loss_arr = decisionTreesModel.train(folds)\n",
    "\n",
    "write_model('browser_decision_tree_model', clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a210cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_acc, loss, report, confusion_matrix = decisionTreesModel.test()\n",
    "print(f\"Loss on test data is: {loss:.3f}\")\n",
    "print(f\"Test accuracy on test data is: {test_acc:.3f}\")\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42453525",
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionTreesModel.get_feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04928093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8423ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "\n",
    "leaves_parallel=False\n",
    "feature_cols = [\"experiment\", \"hour\", \"date\", 'device_make', 'browser']\n",
    "out_put_file = \"AbTestDecisionTree.dot\"\n",
    "\n",
    "dot_data = export_graphviz(clf, out_file=out_put_file,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True, feature_names = feature_cols,class_names=['Aware','Not Aware'])\n",
    "\n",
    "graph = pydotplus.graphviz.graph_from_dot_file(out_put_file)\n",
    "graph.write_png('AbTestDecisionTree.png')\n",
    "\n",
    "Image(graph.create_png())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12db20ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3792c06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_cols = [\"experiment\", \"hour\", \"date\", 'device_make', \"platform_os\",  \"browser\"]\n",
    "feature_cols = [\"experiment\", \"hour\", \"date\", 'device_make', 'platform_os']\n",
    "\n",
    "X = platform_df[feature_cols]\n",
    "y = platform_df[['aware']]\n",
    "\n",
    "test_size = 0.1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa2bcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionTreesModel = DecisionTreesModel(X_train, X_test,  y_train, y_test)\n",
    "\n",
    "folds = 5\n",
    "clf, acc_arr, loss_arr = decisionTreesModel.train(folds)\n",
    "\n",
    "write_model('platform_os_decision_tree_model', clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471b2fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc, loss, report, confusion_matrix = decisionTreesModel.test()\n",
    "print(f\"Loss on test data is: {loss:.3f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a010b17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionTreesModel.get_feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d25cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "\n",
    "leaves_parallel=False\n",
    "feature_cols = [\"experiment\", \"hour\", \"date\", 'device_make', 'browser']\n",
    "out_put_file = \"AbTestDecisionTree.dot\"\n",
    "\n",
    "dot_data = export_graphviz(clf, out_file=out_put_file,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True, feature_names = feature_cols,class_names=['Aware','Not Aware'])\n",
    "\n",
    "graph = pydotplus.graphviz.graph_from_dot_file(out_put_file)\n",
    "graph.write_png('AbTestDecisionTree.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23a3549",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogesticRegressionModel:\n",
    "    \n",
    "    def __init__(self, X_train, X_test, y_train, y_test, model_name=\"LR\"):\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        self.clf = LogisticRegression()\n",
    "        \n",
    "    def train(self, folds=1):\n",
    "        \n",
    "        kf = KFold(n_splits = folds)\n",
    "        \n",
    "        iterator = kf.split(self.X_train)\n",
    "        \n",
    "        loss_arr = []\n",
    "        acc_arr = []\n",
    "        model_name= self.model_name\n",
    "#         mlflow.end_run()\n",
    "        for i in range(folds):\n",
    "\n",
    "            train_index, valid_index = next(iterator)\n",
    "\n",
    "            X_train, y_train = self.X_train.iloc[train_index], self.y_train.iloc[train_index]\n",
    "            X_valid, y_valid = self.X_train.iloc[valid_index], self.y_train.iloc[valid_index]\n",
    "\n",
    "            self.clf = self.clf.fit(X_train, y_train)\n",
    "\n",
    "            vali_pred = self.clf.predict(X_valid)\n",
    "\n",
    "            accuracy = self.calculate_score(y_valid, vali_pred)\n",
    "            loss = loss_function(y_valid, vali_pred)\n",
    "\n",
    "            self.__printAccuracy(accuracy, i, label=\"Validation\")\n",
    "            self.__printLoss(loss, i, label=\"Validation\")\n",
    "            print()\n",
    "\n",
    "            acc_arr.append(accuracy)\n",
    "            loss_arr.append(loss)\n",
    "            \n",
    "        return self.clf, acc_arr, loss_arr\n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.clf.predict(self.X_test)\n",
    "        \n",
    "        accuracy = self.calculate_score(self.y_test, y_pred)\n",
    "        self.__printAccuracy(accuracy, label=\"Test\")\n",
    "        \n",
    "        report = self.report(y_pred, self.y_test)\n",
    "        matrix = self.confusion_matrix(y_pred, self.y_test)\n",
    "        loss = loss_function(self.y_test, y_pred)\n",
    "        \n",
    "        return accuracy, loss, report, matrix \n",
    "    \n",
    "    def __printAccuracy(self, acc, step=1, label=\"\"):\n",
    "        print(f\"step {step}: {label} Accuracy of LogesticRegression is: {acc:.3f}\")\n",
    "    \n",
    "    def __printLoss(self, loss, step=1, label=\"\"):\n",
    "        print(f\"step {step}: {label} Loss of LogesticRegression is: {loss:.3f}\")\n",
    "    \n",
    "    def calculate_score(self, pred, actual):\n",
    "        return metrics.accuracy_score(actual, pred)\n",
    "    \n",
    "    def report(self, pred, actual):\n",
    "        print(\"Test Metrics\")\n",
    "        print(\"================\")\n",
    "        print(metrics.classification_report(pred, actual))\n",
    "        return metrics.classification_report(pred, actual)\n",
    "    \n",
    "    def confusion_matrix(self, pred, actual):\n",
    "        ax=sns.heatmap(pd.DataFrame(metrics.confusion_matrix(pred, actual)))\n",
    "        plt.title('Confusion matrix')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        return metrics.confusion_matrix(pred, actual)\n",
    "    \n",
    "    def get_p_values(self):\n",
    "        \"\"\" \n",
    "        Calcualting p_values for logestic regression.\n",
    "        code refered from the following link\n",
    "        https://gist.github.com/rspeare/77061e6e317896be29c6de9a85db301d\n",
    "        \n",
    "        \"\"\"\n",
    "        denom = (2.0*(1.0+np.cosh(self.clf.decision_function(X))))\n",
    "        denom = np.tile(denom,(X.shape[1],1)).T\n",
    "        F_ij = np.dot((X/denom).T,X) ## Fisher Information Matrix\n",
    "        Cramer_Rao = np.linalg.inv(F_ij) ## Inverse Information Matrix\n",
    "        sigma_estimates = np.sqrt(np.diagonal(Cramer_Rao))\n",
    "        z_scores = self.clf.coef_[0]/sigma_estimates # z-score \n",
    "        p_values = [stat.norm.sf(abs(x)) for x in z_scores] ### two tailed test for p-values\n",
    "        \n",
    "        p_df = pd.DataFrame()\n",
    "        p_df['features'] = self.X_train.columns.to_list()\n",
    "        p_df['p_values'] = p_values\n",
    "        \n",
    "        return p_df\n",
    "    \n",
    "    def plot_pvalues(self, p_df):\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12,7))\n",
    "\n",
    "        ax.plot([0.05,0.05], [0.05,5])\n",
    "        sns.scatterplot(data=p_df, y='features', x='p_values', color=\"green\")\n",
    "        plt.title(\"P values of features\", size=20)\n",
    "\n",
    "        plt.xticks(np.arange(0,max(p_df['p_values']) + 0.05, 0.05))\n",
    "\n",
    "        plt.xticks(fontsize=12)\n",
    "        plt.yticks(fontsize=12)\n",
    "\n",
    "        plt.show()\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e48569",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\"experiment\", \"hour\", \"date\", 'device_make', 'browser']\n",
    "\n",
    "X = browser_df[feature_cols]\n",
    "y = browser_df[['aware']]\n",
    "\n",
    "test_size = 0.1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4a34fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "logesticRegressionModel = LogesticRegressionModel(X_train, X_test,  y_train, y_test)\n",
    "\n",
    "folds = 5\n",
    "clf2, loss_arr_2, acc_arr_2 = logesticRegressionModel.train(folds)\n",
    "\n",
    "write_model('browser_Logestic_Reg_model', clf2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e8ff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc2, test_loss2, report2, matrix2  = logesticRegressionModel.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6134ecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values_df = logesticRegressionModel.get_p_values()\n",
    "p_value_fig = logesticRegressionModel.plot_pvalues(p_values_df)\n",
    "p_values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd04020f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\"experiment\", \"hour\", \"date\", 'device_make', 'platform_os']\n",
    "\n",
    "X = platform_df[feature_cols]\n",
    "y = platform_df[['aware']]\n",
    "\n",
    "test_size = 0.1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4e35da",
   "metadata": {},
   "outputs": [],
   "source": [
    "logesticRegressionModel = LogesticRegressionModel(X_train, X_test,  y_train, y_test)\n",
    "\n",
    "folds = 5\n",
    "clf2, loss_arr_2, acc_arr_2 = logesticRegressionModel.train(folds)\n",
    "\n",
    "write_model('platform_os_Logestic_Reg_model', clf2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8880172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc2, test_loss2, report2, matrix2  = logesticRegressionModel.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a40a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values_df = logesticRegressionModel.get_p_values()\n",
    "p_value_fig = logesticRegressionModel.plot_pvalues(p_values_df)\n",
    "p_values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ea0b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBClassifierModel:\n",
    "    \n",
    "    def __init__(self, X_train, X_test, y_train, y_test, max_depth=5):\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        self.clf = GradientBoostingClassifier()\n",
    "\n",
    "        \n",
    "    def train(self, folds=1):\n",
    "        \n",
    "        kf = KFold(n_splits = folds)\n",
    "        \n",
    "        iterator = kf.split(self.X_train)\n",
    "        \n",
    "        loss_arr = []\n",
    "        acc_arr = []\n",
    "        for i in range(folds):\n",
    "            train_index, valid_index = next(iterator)\n",
    "            \n",
    "            X_train, y_train = self.X_train.iloc[train_index], self.y_train.iloc[train_index]\n",
    "            X_valid, y_valid = self.X_train.iloc[valid_index], self.y_train.iloc[valid_index]\n",
    "                        \n",
    "            self.clf = self.clf.fit(X_train, y_train)\n",
    "            \n",
    "            vali_pred = self.clf.predict(X_valid)\n",
    "            \n",
    "            accuracy = self.calculate_score(y_valid\n",
    "                                              , vali_pred)\n",
    "            \n",
    "            loss = loss_function(y_valid, vali_pred)\n",
    "            \n",
    "            self.__printAccuracy(accuracy, i, label=\"Validation\")\n",
    "            self.__printLoss(loss, i, label=\"Validation\")\n",
    "            print()\n",
    "            \n",
    "            acc_arr.append(accuracy)\n",
    "            loss_arr.append(loss)\n",
    "\n",
    "            \n",
    "        return self.clf, acc_arr, loss_arr\n",
    "    \n",
    "    def test(self):\n",
    "        \n",
    "        y_pred = self.clf.predict(self.X_test)\n",
    "        \n",
    "        accuracy = self.calculate_score(y_pred, self.y_test)\n",
    "        self.__printAccuracy(accuracy, label=\"Test\")\n",
    "        \n",
    "        report = self.report(y_pred, self.y_test)\n",
    "        matrix = self.confusion_matrix(y_pred, self.y_test)\n",
    "        \n",
    "        loss = loss_function(self.y_test, y_pred)\n",
    "        \n",
    "        return accuracy, loss,  report, matrix\n",
    "    \n",
    "    def get_feature_importance(self):\n",
    "        importance = self.clf.feature_importances_\n",
    "        fi_df = pd.DataFrame()\n",
    "        \n",
    "        fi_df['feature'] = self.X_train.columns.to_list()\n",
    "        fi_df['feature_importances'] = importance\n",
    "        \n",
    "        return fi_df\n",
    "    \n",
    "    def __printAccuracy(self, acc, step=1, label=\"\"):\n",
    "        print(f\"step {step}: {label} Accuracy of DecisionTreesModel is: {acc:.3f}\")\n",
    "    \n",
    "    def __printLoss(self, loss, step=1, label=\"\"):\n",
    "        print(f\"step {step}: {label} Loss of DecisionTreesModel is: {loss:.3f}\")\n",
    "    \n",
    "    def calculate_score(self, pred, actual):\n",
    "        return metrics.accuracy_score(actual, pred)\n",
    "    \n",
    "    def report(self, pred, actual):\n",
    "        print(\"Test Metrics\")\n",
    "        print(\"================\")\n",
    "        print(metrics.classification_report(pred, actual))\n",
    "        return metrics.classification_report(pred, actual)\n",
    "    \n",
    "    def confusion_matrix(self, pred, actual):\n",
    "        ax=sns.heatmap(pd.DataFrame(metrics.confusion_matrix(pred, actual)))\n",
    "        plt.title('Confusion matrix')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        return metrics.confusion_matrix(pred, actual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbe83d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_cols = [\"experiment\", \"hour\", \"date\", 'device_make', \"platform_os\",  \"browser\"]\n",
    "feature_cols = [\"experiment\", \"hour\", \"date\", 'device_make', 'browser']\n",
    "\n",
    "X = browser_df[feature_cols]\n",
    "y = browser_df[['aware']]\n",
    "\n",
    "test_size = 0.1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832b2171",
   "metadata": {},
   "outputs": [],
   "source": [
    "xGBClassifierModel = XGBClassifierModel(X_train, X_test,  y_train, y_test)\n",
    "\n",
    "folds = 5\n",
    "clf3, acc_arr, loss_arr = xGBClassifierModel.train(folds)\n",
    "\n",
    "write_model('platform_os_XGBoost_model', clf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9fdee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc, loss, report, confusion_matrix = xGBClassifierModel.test()\n",
    "print(f\"Loss on test data is: {loss:.3f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5d2c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xGBClassifierModel.get_feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf2ef30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d1644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'criterion': ['gini','entropy'], 'max_depth':[4,5,6,7,8,9,10]}\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "gridSearch = GridSearchCV(estimator=clf, param_grid=params, n_jobs=-1,  cv=kfold, scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "\n",
    "import mlflow\n",
    "import datetime\n",
    "Current_Date = datetime.datetime.today()\n",
    "\n",
    "mlflow.set_experiment('DecisionTree-' + str(Current_Date))\n",
    "mlflow.sklearn.autolog()\n",
    "with mlflow.start_run(run_name='DT-Hyperparameter') as run:\n",
    "        searchResults = gridSearch.fit(X_train, y_train)\n",
    "        \n",
    "        pred=searchResults.predict(X_test)\n",
    "        loss=loss_function(y_test,pred)\n",
    "        acc = metrics.accuracy_score(y_test, pred)\n",
    "        \n",
    "        mlflow.log_param('Features', X_train.columns.to_list())\n",
    "        mlflow.log_param('Target', y_train.columns.to_list())\n",
    "        mlflow.log_param('Number Of Training Dataset', X_train.shape[0])\n",
    "        mlflow.log_param('Number Of Test Dataset', X_test.shape[0])\n",
    "        mlflow.log_param('Fold number', folds)\n",
    "                      \n",
    "        \n",
    "\n",
    "        mlflow.log_metric(\"loss\", loss)\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "\n",
    "\n",
    "\n",
    "best_dt_Model = searchResults.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fad547d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924cf14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}\n",
    "kfold = KFold(n_splits=5)\n",
    "\n",
    "mlflow.sklearn.autolog()\n",
    "gridSearch = GridSearchCV(estimator=clf2, param_grid=params, n_jobs=-1,  cv=kfold, scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "mlflow.set_experiment('LogisticRegression-' + str(Current_Date))\n",
    "with mlflow.start_run(run_name='LR-Hyperparameter') as run:\n",
    "        searchResults = gridSearch.fit(X_train, y_train)\n",
    "        \n",
    "        pred=searchResults.predict(X_test)\n",
    "        loss=loss_function(y_test,pred)\n",
    "        acc = metrics.accuracy_score(y_test, pred)\n",
    "        \n",
    "        mlflow.log_param('Features', X_train.columns.to_list())\n",
    "        mlflow.log_param('Target', y_train.columns.to_list())\n",
    "        mlflow.log_param('Number Of Training Dataset', X_train.shape[0])\n",
    "        mlflow.log_param('Number Of Test Dataset', X_test.shape[0])\n",
    "        mlflow.log_param('Fold number', folds)\n",
    "\n",
    "        mlflow.log_metric(\"loss\", loss)\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "        mlflow.log_figure(p_value_fig, 'p_values.png')\n",
    "\n",
    "\n",
    "\n",
    "best_lr_model = searchResults.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b21901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b54eedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'n_estimators': [20, 40, 60, 80]}\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "gridSearch = GridSearchCV(estimator=clf3, param_grid=params, n_jobs=-1,  cv=kfold, scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "\n",
    "import mlflow\n",
    "import datetime\n",
    "Current_Date = datetime.datetime.today()\n",
    "\n",
    "mlflow.set_experiment('XGBoost-' + str(Current_Date))\n",
    "mlflow.sklearn.autolog()\n",
    "with mlflow.start_run(run_name='XGBoost-Hyperparameter') as run:\n",
    "        searchResults = gridSearch.fit(X_train, y_train)\n",
    "        \n",
    "        pred=searchResults.predict(X_test)\n",
    "        loss=loss_function(y_test,pred)\n",
    "        acc = metrics.accuracy_score(y_test, pred)\n",
    "        \n",
    "        mlflow.log_param('Features', X_train.columns.to_list())\n",
    "        mlflow.log_param('Target', y_train.columns.to_list())\n",
    "        mlflow.log_param('Number Of Training Dataset', X_train.shape[0])\n",
    "        mlflow.log_param('Number Of Test Dataset', X_test.shape[0])\n",
    "        mlflow.log_param('Fold number', folds)\n",
    "                      \n",
    "        \n",
    "\n",
    "        mlflow.log_metric(\"loss\", loss)\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "\n",
    "\n",
    "\n",
    "best_dt_Model = searchResults.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be3f48d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c17fd94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf88e01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5be880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7405d19b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4431af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f395f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870bbc35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
