{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0406ed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('../scripts')))\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c882d582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import dvc.api\n",
    "from processing import processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8136d2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from gittypes import tbd\n",
    "import pandas as pd\n",
    "import Plots\n",
    "import scipy.stats as scs\n",
    "import random\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import export_graphviz\n",
    "from six import StringIO\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "from sklearn import tree\n",
    "import scipy.stats as stat\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0bc41f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"../Data/data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9e746a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "processing = processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb7ee50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file read as csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auction_id</th>\n",
       "      <th>experiment</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>device_make</th>\n",
       "      <th>platform_os</th>\n",
       "      <th>browser</th>\n",
       "      <th>yes</th>\n",
       "      <th>no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ef63-77a7-448b-bd1e-075f42c55e39</td>\n",
       "      <td>exposed</td>\n",
       "      <td>2020-07-10</td>\n",
       "      <td>8</td>\n",
       "      <td>Generic Smartphone</td>\n",
       "      <td>6</td>\n",
       "      <td>Chrome Mobile</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000eabc5-17ce-4137-8efe-44734d914446</td>\n",
       "      <td>exposed</td>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>10</td>\n",
       "      <td>Generic Smartphone</td>\n",
       "      <td>6</td>\n",
       "      <td>Chrome Mobile</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0016d14a-ae18-4a02-a204-6ba53b52f2ed</td>\n",
       "      <td>exposed</td>\n",
       "      <td>2020-07-05</td>\n",
       "      <td>2</td>\n",
       "      <td>E5823</td>\n",
       "      <td>6</td>\n",
       "      <td>Chrome Mobile WebView</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00187412-2932-4542-a8ef-3633901c98d9</td>\n",
       "      <td>control</td>\n",
       "      <td>2020-07-03</td>\n",
       "      <td>15</td>\n",
       "      <td>Samsung SM-A705FN</td>\n",
       "      <td>6</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001a7785-d3fe-4e11-a344-c8735acacc2c</td>\n",
       "      <td>control</td>\n",
       "      <td>2020-07-03</td>\n",
       "      <td>15</td>\n",
       "      <td>Generic Smartphone</td>\n",
       "      <td>6</td>\n",
       "      <td>Chrome Mobile</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             auction_id experiment        date  hour  \\\n",
       "0  0008ef63-77a7-448b-bd1e-075f42c55e39    exposed  2020-07-10     8   \n",
       "1  000eabc5-17ce-4137-8efe-44734d914446    exposed  2020-07-07    10   \n",
       "2  0016d14a-ae18-4a02-a204-6ba53b52f2ed    exposed  2020-07-05     2   \n",
       "3  00187412-2932-4542-a8ef-3633901c98d9    control  2020-07-03    15   \n",
       "4  001a7785-d3fe-4e11-a344-c8735acacc2c    control  2020-07-03    15   \n",
       "\n",
       "          device_make  platform_os                browser  yes  no  \n",
       "0  Generic Smartphone            6          Chrome Mobile    0   0  \n",
       "1  Generic Smartphone            6          Chrome Mobile    0   0  \n",
       "2               E5823            6  Chrome Mobile WebView    0   1  \n",
       "3   Samsung SM-A705FN            6               Facebook    0   0  \n",
       "4  Generic Smartphone            6          Chrome Mobile    0   0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= processing.read_csv(csv_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dead5ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(tag, path='Data/clean_data.csv', repo='https://github.com/Maelaf/abtest-mlops'):\n",
    "    rev = tag\n",
    "    data_url = dvc.api.get_url(path=path, repo=repo, rev=rev)\n",
    "    df = pd.read_csv(data_url)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9715b6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def drop_no_responds(df):\n",
    "    cleaned_df = df.query(\"not (yes == 0 & no == 0)\")\n",
    "    return cleaned_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c7fcfd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_model(file_name):\n",
    "    with open(f\"../models/{file_name}.pkl\", \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def write_model(file_name, model):\n",
    "    with open(f\"../models/{file_name}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "958b7ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = drop_no_responds(df)\n",
    "cleaned_df['aware'] = cleaned_df['yes'].map(lambda x: x==1)\n",
    "cleaned_df = cleaned_df.drop(columns = ['yes', 'no', 'auction_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6745fde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cleaned_data():\n",
    "    CLEANED_CSV_PATH = \"../Data/clean_data.csv\"\n",
    "    helper.save_csv(cleaned_df, CLEANED_CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9f7a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9851d47a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc85c7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "def encode_labels(df):\n",
    "    date_encoder = preprocessing.LabelEncoder()\n",
    "    device_encoder = preprocessing.LabelEncoder()\n",
    "    browser_encoder = preprocessing.LabelEncoder()\n",
    "    experiment_encoder = preprocessing.LabelEncoder()\n",
    "    aware_encoder = preprocessing.LabelEncoder()\n",
    "    \n",
    "    df['date'] = date_encoder.fit_transform(df['date'])\n",
    "    df['device_make'] = device_encoder.fit_transform(df['device_make'])\n",
    "    df['browser'] = browser_encoder.fit_transform(df['browser'])\n",
    "    df['experiment'] = experiment_encoder.fit_transform(cleaned_df['experiment'])\n",
    "    df['browser'] = aware_encoder.fit_transform(df['browser'])\n",
    "    df['aware'] = aware_encoder.fit_transform(df['aware'])\n",
    "\n",
    "\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911c4ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "95bc3111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting database\n",
    "\n",
    "def feature_data(cleaned_df):\n",
    "    \n",
    "    broweser_df = cleaned_df[[\"experiment\", \"hour\", \"date\", 'device_make', 'browser', 'aware']]\n",
    "    platfrom_df = cleaned_df[[\"experiment\", \"hour\", \"date\", 'device_make', 'platform_os', 'aware']]\n",
    "\n",
    "    return broweser_df, platfrom_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8664292b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2ff88a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_encoded_df():\n",
    "    \n",
    "    broweser_df, platfrom_df = feature_data(encoded_df)\n",
    "    helper.save_csv(broweser_df, \"../Data/clean_data.csv\")\n",
    "    helper.save_csv(platfrom_df, \"../Data/clean_data.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c183410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede73ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c39c317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d69f2d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreesModel:\n",
    "    \n",
    "    def __init__(self, X_train, X_test, y_train, y_test, max_depth=5):\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        self.clf = DecisionTreeClassifier(max_depth=4)\n",
    "        \n",
    "    def train(self, folds=1):\n",
    "        \n",
    "        kf = KFold(n_splits = folds)\n",
    "        \n",
    "        iterator = kf.split(self.X_train)\n",
    "        \n",
    "        loss_arr = []\n",
    "        acc_arr = []\n",
    "        for i in range(folds):\n",
    "            train_index, valid_index = next(iterator)\n",
    "            \n",
    "            X_train, y_train = self.X_train.iloc[train_index], self.y_train.iloc[train_index]\n",
    "            X_valid, y_valid = self.X_train.iloc[valid_index], self.y_train.iloc[valid_index]\n",
    "                        \n",
    "            self.clf = self.clf.fit(X_train, y_train)\n",
    "            \n",
    "            vali_pred = self.clf.predict(X_valid)\n",
    "            \n",
    "            accuracy = self.calculate_score(y_valid\n",
    "                                              , vali_pred)\n",
    "            \n",
    "            loss = loss_function(y_valid, vali_pred)\n",
    "            \n",
    "            self.__printAccuracy(accuracy, i, label=\"Validation\")\n",
    "            self.__printLoss(loss, i, label=\"Validation\")\n",
    "            print()\n",
    "            \n",
    "            acc_arr.append(accuracy)\n",
    "            loss_arr.append(loss)\n",
    "\n",
    "            \n",
    "        return self.clf, acc_arr, loss_arr\n",
    "    \n",
    "    def test(self):\n",
    "        \n",
    "        y_pred = self.clf.predict(self.X_test)\n",
    "        \n",
    "        accuracy = self.calculate_score(y_pred, self.y_test)\n",
    "        self.__printAccuracy(accuracy, label=\"Test\")\n",
    "        \n",
    "        report = self.report(y_pred, self.y_test)\n",
    "        matrix = self.confusion_matrix(y_pred, self.y_test)\n",
    "        \n",
    "        loss = loss_function(self.y_test, y_pred)\n",
    "        \n",
    "        return accuracy, loss,  report, matrix\n",
    "    \n",
    "    def get_feature_importance(self):\n",
    "        importance = self.clf.feature_importances_\n",
    "        fi_df = pd.DataFrame()\n",
    "        \n",
    "        fi_df['feature'] = self.X_train.columns.to_list()\n",
    "        fi_df['feature_importances'] = importance\n",
    "        \n",
    "        return fi_df\n",
    "    \n",
    "    def __printAccuracy(self, acc, step=1, label=\"\"):\n",
    "        print(f\"step {step}: {label} Accuracy of DecisionTreesModel is: {acc:.3f}\")\n",
    "    \n",
    "    def __printLoss(self, loss, step=1, label=\"\"):\n",
    "        print(f\"step {step}: {label} Loss of DecisionTreesModel is: {loss:.3f}\")\n",
    "    \n",
    "    def calculate_score(self, pred, actual):\n",
    "        return metrics.accuracy_score(actual, pred)\n",
    "    \n",
    "    def report(self, pred, actual):\n",
    "        print(\"Test Metrics\")\n",
    "        print(\"================\")\n",
    "        print(metrics.classification_report(pred, actual))\n",
    "        return metrics.classification_report(pred, actual)\n",
    "    \n",
    "    def confusion_matrix(self, pred, actual):\n",
    "        ax=sns.heatmap(pd.DataFrame(metrics.confusion_matrix(pred, actual)))\n",
    "        plt.title('Confusion matrix')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        return metrics.confusion_matrix(pred, actual)\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9d2cf6e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'typeguard' from 'typing' (C:\\Users\\Maelaf ES\\anaconda3\\lib\\typing.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-d91534692109>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#  from typing_extensions import Protocol\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtypeguard\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplatform_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'enc-platform-df'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbrowser_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'enc-browser-df'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'typeguard' from 'typing' (C:\\Users\\Maelaf ES\\anaconda3\\lib\\typing.py)"
     ]
    }
   ],
   "source": [
    "#  from typing_extensions import Protocol\n",
    "from typing import typeguard\n",
    "platform_df = get_data('enc-platform-df')\n",
    "\n",
    "browser_df = get_data('enc-browser-df')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bb1d68d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Encoded Dataframe containing the the platfrom column\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'platform_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-2a2447213f4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"1. Encoded Dataframe containing the the platfrom column\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplatform_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'platform_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"1. Encoded Dataframe containing the the platfrom column\")\n",
    "platform_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d08b9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Encoded Dataframe containing the the browser column\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'browser_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-d2115bcf57b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"2. Encoded Dataframe containing the the browser column\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbrowser_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'browser_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"2. Encoded Dataframe containing the the browser column\")\n",
    "browser_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f23b062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9042d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf276c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d432092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ca29eac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mlflow\n",
    "# import datetime\n",
    "# Current_Date = datetime.datetime.today()\n",
    "\n",
    "# mlflow.set_experiment('ML_Approach_ABTEST-' + str(Current_Date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227d840e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6f74d548",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'browser_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-29712dc92063>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfeature_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"experiment\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"hour\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"date\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'device_make'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'browser'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbrowser_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature_cols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbrowser_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'aware'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'browser_df' is not defined"
     ]
    }
   ],
   "source": [
    "# feature_cols = [\"experiment\", \"hour\", \"date\", 'device_make', \"platform_os\",  \"browser\"]\n",
    "feature_cols = [\"experiment\", \"hour\", \"date\", 'device_make', 'browser']\n",
    "\n",
    "X = browser_df[feature_cols]\n",
    "y = browser_df[['aware']]\n",
    "\n",
    "test_size = 0.1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d345e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86abbb00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d197e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionTreesModel = DecisionTreesModel(X_train, X_test,  y_train, y_test)\n",
    "\n",
    "folds = 5\n",
    "clf, acc_arr, loss_arr = decisionTreesModel.train(folds)\n",
    "\n",
    "write_model('browser_decision_tree_model', clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be215ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_acc, loss, report, confusion_matrix = decisionTreesModel.test()\n",
    "print(f\"Loss on test data is: {loss:.3f}\")\n",
    "print(f\"Test accuracy on test data is: {test_acc:.3f}\")\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933caf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionTreesModel.get_feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdea961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8313cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "\n",
    "leaves_parallel=False\n",
    "feature_cols = [\"experiment\", \"hour\", \"date\", 'device_make', 'browser']\n",
    "out_put_file = \"AbTestDecisionTree.dot\"\n",
    "\n",
    "dot_data = export_graphviz(clf, out_file=out_put_file,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True, feature_names = feature_cols,class_names=['Aware','Not Aware'])\n",
    "\n",
    "graph = pydotplus.graphviz.graph_from_dot_file(out_put_file)\n",
    "graph.write_png('AbTestDecisionTree.png')\n",
    "\n",
    "Image(graph.create_png())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd2835e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4735139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_cols = [\"experiment\", \"hour\", \"date\", 'device_make', \"platform_os\",  \"browser\"]\n",
    "feature_cols = [\"experiment\", \"hour\", \"date\", 'device_make', 'platform_os']\n",
    "\n",
    "X = platform_df[feature_cols]\n",
    "y = platform_df[['aware']]\n",
    "\n",
    "test_size = 0.1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ed3bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionTreesModel = DecisionTreesModel(X_train, X_test,  y_train, y_test)\n",
    "\n",
    "folds = 5\n",
    "clf, acc_arr, loss_arr = decisionTreesModel.train(folds)\n",
    "\n",
    "write_model('platform_os_decision_tree_model', clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8a9537",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc, loss, report, confusion_matrix = decisionTreesModel.test()\n",
    "print(f\"Loss on test data is: {loss:.3f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd49e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionTreesModel.get_feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b788bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "\n",
    "leaves_parallel=False\n",
    "feature_cols = [\"experiment\", \"hour\", \"date\", 'device_make', 'browser']\n",
    "out_put_file = \"AbTestDecisionTree.dot\"\n",
    "\n",
    "dot_data = export_graphviz(clf, out_file=out_put_file,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True, feature_names = feature_cols,class_names=['Aware','Not Aware'])\n",
    "\n",
    "graph = pydotplus.graphviz.graph_from_dot_file(out_put_file)\n",
    "graph.write_png('AbTestDecisionTree.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efc7995",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogesticRegressionModel:\n",
    "    \n",
    "    def __init__(self, X_train, X_test, y_train, y_test, model_name=\"LR\"):\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        self.clf = LogisticRegression()\n",
    "        \n",
    "    def train(self, folds=1):\n",
    "        \n",
    "        kf = KFold(n_splits = folds)\n",
    "        \n",
    "        iterator = kf.split(self.X_train)\n",
    "        \n",
    "        loss_arr = []\n",
    "        acc_arr = []\n",
    "        model_name= self.model_name\n",
    "#         mlflow.end_run()\n",
    "        for i in range(folds):\n",
    "\n",
    "            train_index, valid_index = next(iterator)\n",
    "\n",
    "            X_train, y_train = self.X_train.iloc[train_index], self.y_train.iloc[train_index]\n",
    "            X_valid, y_valid = self.X_train.iloc[valid_index], self.y_train.iloc[valid_index]\n",
    "\n",
    "            self.clf = self.clf.fit(X_train, y_train)\n",
    "\n",
    "            vali_pred = self.clf.predict(X_valid)\n",
    "\n",
    "            accuracy = self.calculate_score(y_valid, vali_pred)\n",
    "            loss = loss_function(y_valid, vali_pred)\n",
    "\n",
    "            self.__printAccuracy(accuracy, i, label=\"Validation\")\n",
    "            self.__printLoss(loss, i, label=\"Validation\")\n",
    "            print()\n",
    "\n",
    "            acc_arr.append(accuracy)\n",
    "            loss_arr.append(loss)\n",
    "            \n",
    "        return self.clf, acc_arr, loss_arr\n",
    "    \n",
    "    def test(self):\n",
    "        y_pred = self.clf.predict(self.X_test)\n",
    "        \n",
    "        accuracy = self.calculate_score(self.y_test, y_pred)\n",
    "        self.__printAccuracy(accuracy, label=\"Test\")\n",
    "        \n",
    "        report = self.report(y_pred, self.y_test)\n",
    "        matrix = self.confusion_matrix(y_pred, self.y_test)\n",
    "        loss = loss_function(self.y_test, y_pred)\n",
    "        \n",
    "        return accuracy, loss, report, matrix \n",
    "    \n",
    "    def __printAccuracy(self, acc, step=1, label=\"\"):\n",
    "        print(f\"step {step}: {label} Accuracy of LogesticRegression is: {acc:.3f}\")\n",
    "    \n",
    "    def __printLoss(self, loss, step=1, label=\"\"):\n",
    "        print(f\"step {step}: {label} Loss of LogesticRegression is: {loss:.3f}\")\n",
    "    \n",
    "    def calculate_score(self, pred, actual):\n",
    "        return metrics.accuracy_score(actual, pred)\n",
    "    \n",
    "    def report(self, pred, actual):\n",
    "        print(\"Test Metrics\")\n",
    "        print(\"================\")\n",
    "        print(metrics.classification_report(pred, actual))\n",
    "        return metrics.classification_report(pred, actual)\n",
    "    \n",
    "    def confusion_matrix(self, pred, actual):\n",
    "        ax=sns.heatmap(pd.DataFrame(metrics.confusion_matrix(pred, actual)))\n",
    "        plt.title('Confusion matrix')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        return metrics.confusion_matrix(pred, actual)\n",
    "    \n",
    "    def get_p_values(self):\n",
    "        \"\"\" \n",
    "        Calcualting p_values for logestic regression.\n",
    "        code refered from the following link\n",
    "        https://gist.github.com/rspeare/77061e6e317896be29c6de9a85db301d\n",
    "        \n",
    "        \"\"\"\n",
    "        denom = (2.0*(1.0+np.cosh(self.clf.decision_function(X))))\n",
    "        denom = np.tile(denom,(X.shape[1],1)).T\n",
    "        F_ij = np.dot((X/denom).T,X) ## Fisher Information Matrix\n",
    "        Cramer_Rao = np.linalg.inv(F_ij) ## Inverse Information Matrix\n",
    "        sigma_estimates = np.sqrt(np.diagonal(Cramer_Rao))\n",
    "        z_scores = self.clf.coef_[0]/sigma_estimates # z-score \n",
    "        p_values = [stat.norm.sf(abs(x)) for x in z_scores] ### two tailed test for p-values\n",
    "        \n",
    "        p_df = pd.DataFrame()\n",
    "        p_df['features'] = self.X_train.columns.to_list()\n",
    "        p_df['p_values'] = p_values\n",
    "        \n",
    "        return p_df\n",
    "    \n",
    "    def plot_pvalues(self, p_df):\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12,7))\n",
    "\n",
    "        ax.plot([0.05,0.05], [0.05,5])\n",
    "        sns.scatterplot(data=p_df, y='features', x='p_values', color=\"green\")\n",
    "        plt.title(\"P values of features\", size=20)\n",
    "\n",
    "        plt.xticks(np.arange(0,max(p_df['p_values']) + 0.05, 0.05))\n",
    "\n",
    "        plt.xticks(fontsize=12)\n",
    "        plt.yticks(fontsize=12)\n",
    "\n",
    "        plt.show()\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f713a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\"experiment\", \"hour\", \"date\", 'device_make', 'browser']\n",
    "\n",
    "X = browser_df[feature_cols]\n",
    "y = browser_df[['aware']]\n",
    "\n",
    "test_size = 0.1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a890479",
   "metadata": {},
   "outputs": [],
   "source": [
    "logesticRegressionModel = LogesticRegressionModel(X_train, X_test,  y_train, y_test)\n",
    "\n",
    "folds = 5\n",
    "clf2, loss_arr_2, acc_arr_2 = logesticRegressionModel.train(folds)\n",
    "\n",
    "write_model('browser_Logestic_Reg_model', clf2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8674d4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc2, test_loss2, report2, matrix2  = logesticRegressionModel.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1076c8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values_df = logesticRegressionModel.get_p_values()\n",
    "p_value_fig = logesticRegressionModel.plot_pvalues(p_values_df)\n",
    "p_values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c428d128",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\"experiment\", \"hour\", \"date\", 'device_make', 'platform_os']\n",
    "\n",
    "X = platform_df[feature_cols]\n",
    "y = platform_df[['aware']]\n",
    "\n",
    "test_size = 0.1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990ccb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logesticRegressionModel = LogesticRegressionModel(X_train, X_test,  y_train, y_test)\n",
    "\n",
    "folds = 5\n",
    "clf2, loss_arr_2, acc_arr_2 = logesticRegressionModel.train(folds)\n",
    "\n",
    "write_model('platform_os_Logestic_Reg_model', clf2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b28322c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc2, test_loss2, report2, matrix2  = logesticRegressionModel.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad65c60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values_df = logesticRegressionModel.get_p_values()\n",
    "p_value_fig = logesticRegressionModel.plot_pvalues(p_values_df)\n",
    "p_values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f6d364",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBClassifierModel:\n",
    "    \n",
    "    def __init__(self, X_train, X_test, y_train, y_test, max_depth=5):\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        self.clf = GradientBoostingClassifier()\n",
    "\n",
    "        \n",
    "    def train(self, folds=1):\n",
    "        \n",
    "        kf = KFold(n_splits = folds)\n",
    "        \n",
    "        iterator = kf.split(self.X_train)\n",
    "        \n",
    "        loss_arr = []\n",
    "        acc_arr = []\n",
    "        for i in range(folds):\n",
    "            train_index, valid_index = next(iterator)\n",
    "            \n",
    "            X_train, y_train = self.X_train.iloc[train_index], self.y_train.iloc[train_index]\n",
    "            X_valid, y_valid = self.X_train.iloc[valid_index], self.y_train.iloc[valid_index]\n",
    "                        \n",
    "            self.clf = self.clf.fit(X_train, y_train)\n",
    "            \n",
    "            vali_pred = self.clf.predict(X_valid)\n",
    "            \n",
    "            accuracy = self.calculate_score(y_valid\n",
    "                                              , vali_pred)\n",
    "            \n",
    "            loss = loss_function(y_valid, vali_pred)\n",
    "            \n",
    "            self.__printAccuracy(accuracy, i, label=\"Validation\")\n",
    "            self.__printLoss(loss, i, label=\"Validation\")\n",
    "            print()\n",
    "            \n",
    "            acc_arr.append(accuracy)\n",
    "            loss_arr.append(loss)\n",
    "\n",
    "            \n",
    "        return self.clf, acc_arr, loss_arr\n",
    "    \n",
    "    def test(self):\n",
    "        \n",
    "        y_pred = self.clf.predict(self.X_test)\n",
    "        \n",
    "        accuracy = self.calculate_score(y_pred, self.y_test)\n",
    "        self.__printAccuracy(accuracy, label=\"Test\")\n",
    "        \n",
    "        report = self.report(y_pred, self.y_test)\n",
    "        matrix = self.confusion_matrix(y_pred, self.y_test)\n",
    "        \n",
    "        loss = loss_function(self.y_test, y_pred)\n",
    "        \n",
    "        return accuracy, loss,  report, matrix\n",
    "    \n",
    "    def get_feature_importance(self):\n",
    "        importance = self.clf.feature_importances_\n",
    "        fi_df = pd.DataFrame()\n",
    "        \n",
    "        fi_df['feature'] = self.X_train.columns.to_list()\n",
    "        fi_df['feature_importances'] = importance\n",
    "        \n",
    "        return fi_df\n",
    "    \n",
    "    def __printAccuracy(self, acc, step=1, label=\"\"):\n",
    "        print(f\"step {step}: {label} Accuracy of DecisionTreesModel is: {acc:.3f}\")\n",
    "    \n",
    "    def __printLoss(self, loss, step=1, label=\"\"):\n",
    "        print(f\"step {step}: {label} Loss of DecisionTreesModel is: {loss:.3f}\")\n",
    "    \n",
    "    def calculate_score(self, pred, actual):\n",
    "        return metrics.accuracy_score(actual, pred)\n",
    "    \n",
    "    def report(self, pred, actual):\n",
    "        print(\"Test Metrics\")\n",
    "        print(\"================\")\n",
    "        print(metrics.classification_report(pred, actual))\n",
    "        return metrics.classification_report(pred, actual)\n",
    "    \n",
    "    def confusion_matrix(self, pred, actual):\n",
    "        ax=sns.heatmap(pd.DataFrame(metrics.confusion_matrix(pred, actual)))\n",
    "        plt.title('Confusion matrix')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        return metrics.confusion_matrix(pred, actual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bb4970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_cols = [\"experiment\", \"hour\", \"date\", 'device_make', \"platform_os\",  \"browser\"]\n",
    "feature_cols = [\"experiment\", \"hour\", \"date\", 'device_make', 'browser']\n",
    "\n",
    "X = browser_df[feature_cols]\n",
    "y = browser_df[['aware']]\n",
    "\n",
    "test_size = 0.1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e303306",
   "metadata": {},
   "outputs": [],
   "source": [
    "xGBClassifierModel = XGBClassifierModel(X_train, X_test,  y_train, y_test)\n",
    "\n",
    "folds = 5\n",
    "clf3, acc_arr, loss_arr = xGBClassifierModel.train(folds)\n",
    "\n",
    "write_model('platform_os_XGBoost_model', clf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76912778",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc, loss, report, confusion_matrix = xGBClassifierModel.test()\n",
    "print(f\"Loss on test data is: {loss:.3f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696f2102",
   "metadata": {},
   "outputs": [],
   "source": [
    "xGBClassifierModel.get_feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34f9f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd49fad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'criterion': ['gini','entropy'], 'max_depth':[4,5,6,7,8,9,10]}\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "gridSearch = GridSearchCV(estimator=clf, param_grid=params, n_jobs=-1,  cv=kfold, scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "\n",
    "import mlflow\n",
    "import datetime\n",
    "Current_Date = datetime.datetime.today()\n",
    "\n",
    "mlflow.set_experiment('DecisionTree-' + str(Current_Date))\n",
    "mlflow.sklearn.autolog()\n",
    "with mlflow.start_run(run_name='DT-Hyperparameter') as run:\n",
    "        searchResults = gridSearch.fit(X_train, y_train)\n",
    "        \n",
    "        pred=searchResults.predict(X_test)\n",
    "        loss=loss_function(y_test,pred)\n",
    "        acc = metrics.accuracy_score(y_test, pred)\n",
    "        \n",
    "        mlflow.log_param('Features', X_train.columns.to_list())\n",
    "        mlflow.log_param('Target', y_train.columns.to_list())\n",
    "        mlflow.log_param('Number Of Training Dataset', X_train.shape[0])\n",
    "        mlflow.log_param('Number Of Test Dataset', X_test.shape[0])\n",
    "        mlflow.log_param('Fold number', folds)\n",
    "                      \n",
    "        \n",
    "\n",
    "        mlflow.log_metric(\"loss\", loss)\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "\n",
    "\n",
    "\n",
    "best_dt_Model = searchResults.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95831db7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736badf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}\n",
    "kfold = KFold(n_splits=5)\n",
    "\n",
    "mlflow.sklearn.autolog()\n",
    "gridSearch = GridSearchCV(estimator=clf2, param_grid=params, n_jobs=-1,  cv=kfold, scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "mlflow.set_experiment('LogisticRegression-' + str(Current_Date))\n",
    "with mlflow.start_run(run_name='LR-Hyperparameter') as run:\n",
    "        searchResults = gridSearch.fit(X_train, y_train)\n",
    "        \n",
    "        pred=searchResults.predict(X_test)\n",
    "        loss=loss_function(y_test,pred)\n",
    "        acc = metrics.accuracy_score(y_test, pred)\n",
    "        \n",
    "        mlflow.log_param('Features', X_train.columns.to_list())\n",
    "        mlflow.log_param('Target', y_train.columns.to_list())\n",
    "        mlflow.log_param('Number Of Training Dataset', X_train.shape[0])\n",
    "        mlflow.log_param('Number Of Test Dataset', X_test.shape[0])\n",
    "        mlflow.log_param('Fold number', folds)\n",
    "\n",
    "        mlflow.log_metric(\"loss\", loss)\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "        mlflow.log_figure(p_value_fig, 'p_values.png')\n",
    "\n",
    "\n",
    "\n",
    "best_lr_model = searchResults.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08e7589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e038f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'n_estimators': [20, 40, 60, 80]}\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "gridSearch = GridSearchCV(estimator=clf3, param_grid=params, n_jobs=-1,  cv=kfold, scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "\n",
    "import mlflow\n",
    "import datetime\n",
    "Current_Date = datetime.datetime.today()\n",
    "\n",
    "mlflow.set_experiment('XGBoost-' + str(Current_Date))\n",
    "mlflow.sklearn.autolog()\n",
    "with mlflow.start_run(run_name='XGBoost-Hyperparameter') as run:\n",
    "        searchResults = gridSearch.fit(X_train, y_train)\n",
    "        \n",
    "        pred=searchResults.predict(X_test)\n",
    "        loss=loss_function(y_test,pred)\n",
    "        acc = metrics.accuracy_score(y_test, pred)\n",
    "        \n",
    "        mlflow.log_param('Features', X_train.columns.to_list())\n",
    "        mlflow.log_param('Target', y_train.columns.to_list())\n",
    "        mlflow.log_param('Number Of Training Dataset', X_train.shape[0])\n",
    "        mlflow.log_param('Number Of Test Dataset', X_test.shape[0])\n",
    "        mlflow.log_param('Fold number', folds)\n",
    "                      \n",
    "        \n",
    "\n",
    "        mlflow.log_metric(\"loss\", loss)\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "\n",
    "\n",
    "\n",
    "best_dt_Model = searchResults.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdb1f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eae22f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c550786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed574d71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c53ded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27c2451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ee679a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83c3870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
